{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from src.simple_pointnet.variance_pointnet import VariancePointNet\n",
    "from src.dspn.SetDSPN import SetDSPN\n",
    "from datasets.MinatarDataset.MinatarDataset import MinatarDataset\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Square linear\n",
    "dataset = MinatarDataset()\n",
    "dim_dict = dataset.get_dims()\n",
    "env_len = dim_dict[\"action_len\"]\n",
    "obj_in_len = dim_dict[\"obj_len\"]\n",
    "obj_reg_len = 2\n",
    "obj_attri_len = 2\n",
    "out_set_size = 10\n",
    "hidden_dim = 512\n",
    "\n",
    "# Prepare the dataloader\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, dataset_size - train_size])\n",
    "train_data_loader = DataLoader(train_set, batch_size=1, shuffle=True)  # num_workers=8, pin_memory=True,\n",
    "val_data_loader = DataLoader(val_set, batch_size=1, pin_memory=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = SetDSPN(\n",
    "    obj_in_len=obj_in_len,\n",
    "    obj_reg_len=2,\n",
    "    obj_attri_len=2,\n",
    "    env_len=env_len,\n",
    "    latent_dim=64,\n",
    "    out_set_size=2,\n",
    "    n_iters=10,\n",
    "    masks=False\n",
    ")\n",
    "\n",
    "# Early stop callback\n",
    "# early_stop_callback = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     min_delta=0.00,\n",
    "#     patience=3,\n",
    "#     verbose=False,\n",
    "#     mode='min'\n",
    "# )\n",
    "\n",
    "# Native train\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# for i, batch in enumerate(train_data_loader):\n",
    "#     print(i)\n",
    "#     s, a, sprime, sappear, r = batch\n",
    "#     s, a, sappear = s.to(model.device), a.to(model.device), sappear.to(model.device)\n",
    "#     pred = model(s, a)\n",
    "#     losses = model.loss_fn(pred, sappear)\n",
    "#\n",
    "#     optimizer.zero_grad()\n",
    "#     losses['loss_encoder'].backward()\n",
    "#     optimizer.step()\n",
    "#     pass\n",
    "\n",
    "\n",
    "# Train\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    max_epochs=12,\n",
    "    # check_val_every_n_epoch=4,\n",
    "    accumulate_grad_batches=64,\n",
    "    profiler=\"simple\"\n",
    "    # callbacks=[early_stop_callback]\n",
    ")\n",
    "trainer.fit(model, train_data_loader, val_data_loader)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Train\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def visualize(pred, s, gt_sprime, gt_sappear):\n",
    "    # Extract the information\n",
    "    pred_mask = pred['pred_mask'][0].detach()\n",
    "    pred_pos = pred['pred_reg'][0][:, 0:2].detach()\n",
    "    pred_pos_var = pred['pred_reg_var'][0][:, 0:2].detach()\n",
    "    pred_pos_var = pred_pos_var[:, 0] + pred_pos_var[:, 1]\n",
    "\n",
    "    # Plot predictions\n",
    "    pred_data = {\n",
    "        \"x\": pred_pos[:, 0],\n",
    "        \"y\": pred_pos[:, 1],\n",
    "        \"var\": pred_pos_var,\n",
    "        \"vis\": pred_mask\n",
    "    }\n",
    "    sns.relplot(\n",
    "        data=pred_data, x='x', y='y',\n",
    "        size='var', alpha=0.5,\n",
    "        legend=False\n",
    "    )\n",
    "\n",
    "    # Plot ground truth\n",
    "    if len(gt_sappear) != 0:\n",
    "        gt_data = {\n",
    "            \"x\": gt_sappear[:, 0],\n",
    "            \"y\": gt_sappear[:, 1]\n",
    "        }\n",
    "        plt.plot(gt_sappear[:, 0], gt_sappear[:, 1], 'rx')\n",
    "        print(gt_sappear)\n",
    "    plt.plot(gt_sprime[:, 0], gt_sprime[:, 1], 'kx')\n",
    "    plt.plot(s[:, 0], s[:, 1], 'ko')\n",
    "\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Vsiualization\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = None\n",
    "# load model\n",
    "if model is None:\n",
    "    if path is None:\n",
    "        list_ckpts = glob.glob(os.path.join(\"lightning_logs\", \"*\", \"checkpoints\", \"*.ckpt\"))\n",
    "        latest_ckpt = max(list_ckpts, key=os.path.getctime)\n",
    "        print(\"Using checkpoint \", latest_ckpt)\n",
    "        path = latest_ckpt\n",
    "\n",
    "    model = SetDSPN.load_from_checkpoint(path)\n",
    "    # model.freeze()\n",
    "\n",
    "# Evaluate\n",
    "dataset = MinatarDataset()\n",
    "eval_data_loader = DataLoader(dataset, batch_size=1)\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    batch_idx = random.randint(0, len(dataset))\n",
    "    batch = dataset[batch_idx]\n",
    "    s, a, sprime, sappear, r = batch\n",
    "    pred = model(s.unsqueeze(0), a.unsqueeze(0))\n",
    "    visualize(pred, s, sprime, sappear)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Validation\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}