{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DSPN import settoset, hungarian_loss \n",
    "import scipy.optimize\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import numpy as np \n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from fspool import FSPool\n",
    "class FSEncoder(nn.Module):\n",
    "    ##Set encoder from the DSPN/FSencoder papers\n",
    "    def __init__(self, input_channels, output_channels, dim,set_dim, mask = False):\n",
    "        super().__init__()\n",
    "        self.set_dim = set_dim\n",
    "        n_out = 30\n",
    "        if mask == True: \n",
    "            self.mask = 1 \n",
    "        else: \n",
    "            self.mask = 0\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_channels + self.mask, dim, 1),\n",
    "           ## nn.ReLU(),\n",
    "           ## nn.Conv1d(dim, dim, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(dim, output_channels, 1),\n",
    "        )\n",
    "        self.pool = FSPool(output_channels, n_out, relaxed=False)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        ##mask = mask.unsqueeze(1)\n",
    "        ##x = torch.cat([x, mask], dim=1)  # include mask as part of set\n",
    "        x = x.reshape((self.set_dim[1],-1)).unsqueeze(2).permute(2,0,1)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = x / x.size(2)  # normalise so that activations aren't too high with big sets\n",
    "        x, _ = self.pool(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "    \n",
    "import csv\n",
    "import json \n",
    "\n",
    "##Dataset class for predicting new objects from the currect state\n",
    "class newobjectdataset(Dataset): \n",
    "    def __init__(self, data_root, label_dim = 1):\n",
    "      \n",
    "        self.data = []\n",
    "        \n",
    "        self.label_dim = label_dim\n",
    "        results = []\n",
    "        with open(data_root) as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter = \"|\") # change contents to floats\n",
    "            for row in reader: # each row is a list\n",
    "                dataentry = json.loads(row[0])\n",
    "                results.append(dataentry)\n",
    "        self.data = results\n",
    "        \n",
    "    def __getitem__(self,idx): \n",
    "        return torch.Tensor(self.data[2*idx]), torch.Tensor(self.data[2*idx + 1])\n",
    "    def __len__(self): \n",
    "        return int(len(self.data)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(72.9373, grad_fn=<AddBackward0>)\n",
      "tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "tensor([0.7413, 0.9475], grad_fn=<SubBackward0>)\n",
      "tensor(29.2179, grad_fn=<AddBackward0>)\n",
      "tensor(0.0139, grad_fn=<AddBackward0>)\n",
      "tensor([0.6569, 0.6903], grad_fn=<SubBackward0>)\n",
      "tensor(24.7251, grad_fn=<AddBackward0>)\n",
      "tensor(0.0535, grad_fn=<AddBackward0>)\n",
      "tensor([0.9472, 0.3216], grad_fn=<SubBackward0>)\n",
      "tensor(24.3917, grad_fn=<AddBackward0>)\n",
      "tensor(0.0148, grad_fn=<AddBackward0>)\n",
      "tensor([0.8025, 0.4348], grad_fn=<SubBackward0>)\n",
      "tensor(28.7355, grad_fn=<AddBackward0>)\n",
      "tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "tensor([0.7492, 0.5218], grad_fn=<SubBackward0>)\n",
      "tensor(29.6673, grad_fn=<AddBackward0>)\n",
      "tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "tensor([0.7324, 0.2534], grad_fn=<SubBackward0>)\n",
      "tensor(26.7821, grad_fn=<AddBackward0>)\n",
      "tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "tensor([0.8359, 0.4084], grad_fn=<SubBackward0>)\n",
      "tensor(19.6304, grad_fn=<AddBackward0>)\n",
      "tensor(0.0097, grad_fn=<AddBackward0>)\n",
      "tensor([0.8348, 0.1741], grad_fn=<SubBackward0>)\n",
      "tensor(19.3347, grad_fn=<AddBackward0>)\n",
      "tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "tensor([0.3300, 0.2014], grad_fn=<SubBackward0>)\n",
      "tensor(25.3357, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor([0.7367, 0.6482], grad_fn=<SubBackward0>)\n",
      "tensor(21.6538, grad_fn=<AddBackward0>)\n",
      "tensor(0.0141, grad_fn=<AddBackward0>)\n",
      "tensor([0.2835, 0.6758], grad_fn=<SubBackward0>)\n",
      "tensor(20.2550, grad_fn=<AddBackward0>)\n",
      "tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "tensor([0.1211, 0.5963], grad_fn=<SubBackward0>)\n",
      "tensor(10.8066, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor([0.4363, 0.8031], grad_fn=<SubBackward0>)\n",
      "tensor(6.3263, grad_fn=<AddBackward0>)\n",
      "tensor(0.0198, grad_fn=<AddBackward0>)\n",
      "tensor([0.4594, 0.5937], grad_fn=<SubBackward0>)\n",
      "tensor(6.9101, grad_fn=<AddBackward0>)\n",
      "tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "tensor([0.3287, 0.5189], grad_fn=<SubBackward0>)\n",
      "tensor(5.0626, grad_fn=<AddBackward0>)\n",
      "tensor(0.0144, grad_fn=<AddBackward0>)\n",
      "tensor([0.4924, 0.7534], grad_fn=<SubBackward0>)\n",
      "tensor(5.5914, grad_fn=<AddBackward0>)\n",
      "tensor(0.0028, grad_fn=<AddBackward0>)\n",
      "tensor([0.5620, 0.7366], grad_fn=<SubBackward0>)\n",
      "tensor(4.3841, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor([0.4703, 0.8770], grad_fn=<SubBackward0>)\n",
      "tensor(4.5588, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.4916, 0.5860], grad_fn=<SubBackward0>)\n",
      "tensor(3.9936, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.2158, 0.7159], grad_fn=<SubBackward0>)\n",
      "tensor(4.8933, grad_fn=<AddBackward0>)\n",
      "tensor(7.3513e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.0916, 0.3016], grad_fn=<SubBackward0>)\n",
      "tensor(4.2766, grad_fn=<AddBackward0>)\n",
      "tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "tensor([0.3462, 0.4279], grad_fn=<SubBackward0>)\n",
      "tensor(4.0587, grad_fn=<AddBackward0>)\n",
      "tensor(8.0983e-06, grad_fn=<AddBackward0>)\n",
      "tensor([0.3995, 0.5972], grad_fn=<SubBackward0>)\n",
      "tensor(4.7691, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.1121, 0.3870], grad_fn=<SubBackward0>)\n",
      "tensor(4.4614, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.3852, 0.7809], grad_fn=<SubBackward0>)\n",
      "tensor(3.8913, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor([0.3596, 0.6585], grad_fn=<SubBackward0>)\n",
      "tensor(4.8267, grad_fn=<AddBackward0>)\n",
      "tensor(2.7085e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.1038, 0.0964], grad_fn=<SubBackward0>)\n",
      "tensor(3.4652, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor([0.6155, 0.9450], grad_fn=<SubBackward0>)\n",
      "tensor(4.3053, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.3823, 0.5142], grad_fn=<SubBackward0>)\n",
      "tensor(3.5480, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor([0.1994, 0.7739], grad_fn=<SubBackward0>)\n",
      "tensor(4.5977, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor([0.4068, 0.4707], grad_fn=<SubBackward0>)\n",
      "tensor(3.7341, grad_fn=<AddBackward0>)\n",
      "tensor(0.0238, grad_fn=<AddBackward0>)\n",
      "tensor([0.2581, 0.6486], grad_fn=<SubBackward0>)\n",
      "tensor(3.4519, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.3119, 0.5970], grad_fn=<SubBackward0>)\n",
      "tensor(4.0788, grad_fn=<AddBackward0>)\n",
      "tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "tensor([0.3493, 0.4395], grad_fn=<SubBackward0>)\n",
      "tensor(4.8354, grad_fn=<AddBackward0>)\n",
      "tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "tensor([0.3902, 0.8029], grad_fn=<SubBackward0>)\n",
      "tensor(3.3508, grad_fn=<AddBackward0>)\n",
      "tensor(5.4920e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.2926, 0.5009], grad_fn=<SubBackward0>)\n",
      "tensor(3.4702, grad_fn=<AddBackward0>)\n",
      "tensor(1.5676e-06, grad_fn=<AddBackward0>)\n",
      "tensor([0.2991, 0.3992], grad_fn=<SubBackward0>)\n",
      "tensor(3.5843, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor([0.0595, 0.0833], grad_fn=<SubBackward0>)\n",
      "tensor(3.9040, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor([0.0259, 0.4071], grad_fn=<SubBackward0>)\n",
      "tensor(3.9360, grad_fn=<AddBackward0>)\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "tensor([0.0042, 0.5199], grad_fn=<SubBackward0>)\n",
      "tensor(3.3527, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor([0.5777, 0.6830], grad_fn=<SubBackward0>)\n",
      "tensor(4.8586, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "tensor([0.4702, 0.5095], grad_fn=<SubBackward0>)\n",
      "tensor(4.3489, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.2923, 0.7931], grad_fn=<SubBackward0>)\n",
      "tensor(4.1308, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.3082, 0.5848], grad_fn=<SubBackward0>)\n",
      "tensor(4.3384, grad_fn=<AddBackward0>)\n",
      "tensor(0.0281, grad_fn=<AddBackward0>)\n",
      "tensor([0.6720, 0.7919], grad_fn=<SubBackward0>)\n",
      "tensor(3.5942, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor([0.4299, 0.6150], grad_fn=<SubBackward0>)\n",
      "tensor(3.8674, grad_fn=<AddBackward0>)\n",
      "tensor(0.0018, grad_fn=<AddBackward0>)\n",
      "tensor([0.0740, 0.4658], grad_fn=<SubBackward0>)\n",
      "tensor(3.5575, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.0895, 0.9207], grad_fn=<SubBackward0>)\n",
      "tensor(3.8146, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor([0.5387, 0.8893], grad_fn=<SubBackward0>)\n",
      "tensor(3.9642, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor([0.4644, 0.5816], grad_fn=<SubBackward0>)\n",
      "tensor(3.7185, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor([0.1589, 0.6956], grad_fn=<SubBackward0>)\n",
      "tensor(4.3421, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.1204, 0.3937], grad_fn=<SubBackward0>)\n",
      "tensor(3.4241, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.1009, 0.6749], grad_fn=<SubBackward0>)\n",
      "tensor(3.8459, grad_fn=<AddBackward0>)\n",
      "tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "tensor([0.5603, 0.6253], grad_fn=<SubBackward0>)\n",
      "tensor(3.4247, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor([0.5011, 0.7669], grad_fn=<SubBackward0>)\n",
      "tensor(3.3575, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.2093, 0.4200], grad_fn=<SubBackward0>)\n",
      "tensor(3.9178, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor([0.2875, 0.4544], grad_fn=<SubBackward0>)\n",
      "tensor(3.9821, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.0943, 0.2087], grad_fn=<SubBackward0>)\n",
      "tensor(4.1116, grad_fn=<AddBackward0>)\n",
      "tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "tensor([0.3819, 0.7575], grad_fn=<SubBackward0>)\n",
      "tensor(3.2833, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.5219, 0.6973], grad_fn=<SubBackward0>)\n",
      "tensor(3.6983, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor([0.1305, 0.4213], grad_fn=<SubBackward0>)\n",
      "tensor(3.0933, grad_fn=<AddBackward0>)\n",
      "tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "tensor([0.2123, 0.2729], grad_fn=<SubBackward0>)\n",
      "tensor(4.3619, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor([0.3761, 0.7850], grad_fn=<SubBackward0>)\n",
      "tensor(2.7953, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.8129, 0.7993], grad_fn=<SubBackward0>)\n",
      "tensor(4.3335, grad_fn=<AddBackward0>)\n",
      "tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "tensor([0.1491, 0.3126], grad_fn=<SubBackward0>)\n",
      "tensor(3.4486, grad_fn=<AddBackward0>)\n",
      "tensor(2.4512e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.0971, 0.8040], grad_fn=<SubBackward0>)\n",
      "tensor(3.5529, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor([0.7483, 0.7612], grad_fn=<SubBackward0>)\n",
      "tensor(3.0419, grad_fn=<AddBackward0>)\n",
      "tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "tensor([0.7669, 0.7908], grad_fn=<SubBackward0>)\n",
      "tensor(3.8244, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor([0.4306, 0.4883], grad_fn=<SubBackward0>)\n",
      "tensor(0.5499, grad_fn=<AddBackward0>)\n",
      "tensor(4.2082, grad_fn=<AddBackward0>)\n",
      "tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "tensor([0.7301, 0.7501], grad_fn=<SubBackward0>)\n",
      "tensor(3.4141, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.7092, 0.7795], grad_fn=<SubBackward0>)\n",
      "tensor(3.0821, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor([0.4692, 0.8367], grad_fn=<SubBackward0>)\n",
      "tensor(3.6050, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.4960, 0.6887], grad_fn=<SubBackward0>)\n",
      "tensor(3.7617, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.5035, 0.7874], grad_fn=<SubBackward0>)\n",
      "tensor(3.1277, grad_fn=<AddBackward0>)\n",
      "tensor(0.0456, grad_fn=<AddBackward0>)\n",
      "tensor([0.3019, 0.6796], grad_fn=<SubBackward0>)\n",
      "tensor(4.0509, grad_fn=<AddBackward0>)\n",
      "tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "tensor([0.6483, 0.6781], grad_fn=<SubBackward0>)\n",
      "tensor(3.6222, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor([0.1002, 0.8623], grad_fn=<SubBackward0>)\n",
      "tensor(3.5347, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.1231, 0.3926], grad_fn=<SubBackward0>)\n",
      "tensor(3.0367, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor([0.6433, 0.7030], grad_fn=<SubBackward0>)\n",
      "tensor(3.4726, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.3874, 0.6818], grad_fn=<SubBackward0>)\n",
      "tensor(3.8810, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor([0.2785, 0.4349], grad_fn=<SubBackward0>)\n",
      "tensor(3.2945, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.4042, 0.8108], grad_fn=<SubBackward0>)\n",
      "tensor(3.8426, grad_fn=<AddBackward0>)\n",
      "tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "tensor([0.5070, 0.5948], grad_fn=<SubBackward0>)\n",
      "tensor(4.0411, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor([0.3784, 0.4851], grad_fn=<SubBackward0>)\n",
      "tensor(2.8559, grad_fn=<AddBackward0>)\n",
      "tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "tensor([0.5532, 0.7020], grad_fn=<SubBackward0>)\n",
      "tensor(3.0830, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.5896, 0.7190], grad_fn=<SubBackward0>)\n",
      "tensor(3.0010, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor([0.4542, 0.8871], grad_fn=<SubBackward0>)\n",
      "tensor(3.1894, grad_fn=<AddBackward0>)\n",
      "tensor(7.5747e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.5030, 0.6082], grad_fn=<SubBackward0>)\n",
      "tensor(2.7418, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor([0.2015, 0.7291], grad_fn=<SubBackward0>)\n",
      "tensor(3.4770, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.0954, 0.3103], grad_fn=<SubBackward0>)\n",
      "tensor(3.2966, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor([0.3680, 0.4126], grad_fn=<SubBackward0>)\n",
      "tensor(3.1307, grad_fn=<AddBackward0>)\n",
      "tensor(7.4306e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.3966, 0.6079], grad_fn=<SubBackward0>)\n",
      "tensor(3.6486, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.1218, 0.3985], grad_fn=<SubBackward0>)\n",
      "tensor(3.2189, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.3838, 0.7926], grad_fn=<SubBackward0>)\n",
      "tensor(2.9432, grad_fn=<AddBackward0>)\n",
      "tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "tensor([0.3424, 0.6297], grad_fn=<SubBackward0>)\n",
      "tensor(3.5567, grad_fn=<AddBackward0>)\n",
      "tensor(4.9816e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.0989, 0.1070], grad_fn=<SubBackward0>)\n",
      "tensor(2.4985, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor([0.6162, 0.9347], grad_fn=<SubBackward0>)\n",
      "tensor(3.2432, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.3867, 0.5066], grad_fn=<SubBackward0>)\n",
      "tensor(2.9373, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.2005, 0.8121], grad_fn=<SubBackward0>)\n",
      "tensor(3.4133, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.4207, 0.4852], grad_fn=<SubBackward0>)\n",
      "tensor(3.1437, grad_fn=<AddBackward0>)\n",
      "tensor(0.0137, grad_fn=<AddBackward0>)\n",
      "tensor([0.2739, 0.6143], grad_fn=<SubBackward0>)\n",
      "tensor(2.7288, grad_fn=<AddBackward0>)\n",
      "tensor(7.8373e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.3053, 0.5929], grad_fn=<SubBackward0>)\n",
      "tensor(3.4051, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor([0.3767, 0.4149], grad_fn=<SubBackward0>)\n",
      "tensor(3.8530, grad_fn=<AddBackward0>)\n",
      "tensor(0.0092, grad_fn=<AddBackward0>)\n",
      "tensor([0.3960, 0.7993], grad_fn=<SubBackward0>)\n",
      "tensor(2.7823, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.2872, 0.4922], grad_fn=<SubBackward0>)\n",
      "tensor(2.6901, grad_fn=<AddBackward0>)\n",
      "tensor(4.6357e-06, grad_fn=<AddBackward0>)\n",
      "tensor([0.3022, 0.4000], grad_fn=<SubBackward0>)\n",
      "tensor(3.0002, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.0827, 0.0010], grad_fn=<SubBackward0>)\n",
      "tensor(3.3295, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.0185, 0.4146], grad_fn=<SubBackward0>)\n",
      "tensor(3.2611, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor([-0.0166,  0.5258], grad_fn=<SubBackward0>)\n",
      "tensor(2.8720, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.5829, 0.6973], grad_fn=<SubBackward0>)\n",
      "tensor(3.9738, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.4782, 0.5111], grad_fn=<SubBackward0>)\n",
      "tensor(3.6039, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.2920, 0.8061], grad_fn=<SubBackward0>)\n",
      "tensor(3.5666, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.3075, 0.5901], grad_fn=<SubBackward0>)\n",
      "tensor(3.6470, grad_fn=<AddBackward0>)\n",
      "tensor(0.0277, grad_fn=<AddBackward0>)\n",
      "tensor([0.6745, 0.7906], grad_fn=<SubBackward0>)\n",
      "tensor(2.9349, grad_fn=<AddBackward0>)\n",
      "tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "tensor([0.4209, 0.6117], grad_fn=<SubBackward0>)\n",
      "tensor(3.0909, grad_fn=<AddBackward0>)\n",
      "tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "tensor([0.0663, 0.4500], grad_fn=<SubBackward0>)\n",
      "tensor(2.9760, grad_fn=<AddBackward0>)\n",
      "tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "tensor([0.0467, 0.9307], grad_fn=<SubBackward0>)\n",
      "tensor(3.2886, grad_fn=<AddBackward0>)\n",
      "tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "tensor([0.5381, 0.8960], grad_fn=<SubBackward0>)\n",
      "tensor(3.2012, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor([0.4628, 0.5966], grad_fn=<SubBackward0>)\n",
      "tensor(3.1609, grad_fn=<AddBackward0>)\n",
      "tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "tensor([0.1726, 0.7130], grad_fn=<SubBackward0>)\n",
      "tensor(3.6466, grad_fn=<AddBackward0>)\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "tensor([0.1102, 0.3819], grad_fn=<SubBackward0>)\n",
      "tensor(2.9943, grad_fn=<AddBackward0>)\n",
      "tensor(3.8124e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.1020, 0.6941], grad_fn=<SubBackward0>)\n",
      "tensor(3.3224, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor([0.5282, 0.6191], grad_fn=<SubBackward0>)\n",
      "tensor(2.6711, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.4959, 0.7786], grad_fn=<SubBackward0>)\n",
      "tensor(2.8270, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.2015, 0.4140], grad_fn=<SubBackward0>)\n",
      "tensor(3.3693, grad_fn=<AddBackward0>)\n",
      "tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "tensor([0.3060, 0.4649], grad_fn=<SubBackward0>)\n",
      "tensor(3.4449, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor([0.0814, 0.2330], grad_fn=<SubBackward0>)\n",
      "tensor(3.4403, grad_fn=<AddBackward0>)\n",
      "tensor(0.0010, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3916, 0.7694], grad_fn=<SubBackward0>)\n",
      "tensor(2.7894, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.5175, 0.6994], grad_fn=<SubBackward0>)\n",
      "tensor(3.1762, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor([0.1218, 0.4253], grad_fn=<SubBackward0>)\n",
      "tensor(2.6432, grad_fn=<AddBackward0>)\n",
      "tensor(0.0030, grad_fn=<AddBackward0>)\n",
      "tensor([0.1841, 0.2523], grad_fn=<SubBackward0>)\n",
      "tensor(3.7165, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.4214, 0.7988], grad_fn=<SubBackward0>)\n",
      "tensor(2.5122, grad_fn=<AddBackward0>)\n",
      "tensor(3.1870e-05, grad_fn=<AddBackward0>)\n",
      "tensor([0.7958, 0.7962], grad_fn=<SubBackward0>)\n",
      "tensor(3.8484, grad_fn=<AddBackward0>)\n",
      "tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "tensor([0.1239, 0.3134], grad_fn=<SubBackward0>)\n",
      "tensor(2.9848, grad_fn=<AddBackward0>)\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "tensor([0.0901, 0.8187], grad_fn=<SubBackward0>)\n",
      "tensor(3.0973, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor([0.7252, 0.7694], grad_fn=<SubBackward0>)\n",
      "tensor(2.5727, grad_fn=<AddBackward0>)\n",
      "tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "tensor([0.7426, 0.7790], grad_fn=<SubBackward0>)\n",
      "tensor(3.5262, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor([0.4241, 0.4846], grad_fn=<SubBackward0>)\n",
      "tensor(0.4488, grad_fn=<AddBackward0>)\n",
      "tensor(3.7760, grad_fn=<AddBackward0>)\n",
      "tensor(0.0014, grad_fn=<AddBackward0>)\n",
      "tensor([0.7100, 0.7367], grad_fn=<SubBackward0>)\n",
      "tensor(2.9758, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.6950, 0.7874], grad_fn=<SubBackward0>)\n",
      "tensor(2.7392, grad_fn=<AddBackward0>)\n",
      "tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "tensor([0.4915, 0.8268], grad_fn=<SubBackward0>)\n",
      "tensor(3.2418, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.4895, 0.6885], grad_fn=<SubBackward0>)\n",
      "tensor(3.2640, grad_fn=<AddBackward0>)\n",
      "tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "tensor([0.4993, 0.7790], grad_fn=<SubBackward0>)\n",
      "tensor(2.7564, grad_fn=<AddBackward0>)\n",
      "tensor(0.0470, grad_fn=<AddBackward0>)\n",
      "tensor([0.2997, 0.6832], grad_fn=<SubBackward0>)\n",
      "tensor(3.7327, grad_fn=<AddBackward0>)\n",
      "tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "tensor([0.6623, 0.6854], grad_fn=<SubBackward0>)\n",
      "tensor(3.2315, grad_fn=<AddBackward0>)\n",
      "tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "tensor([0.0808, 0.8710], grad_fn=<SubBackward0>)\n",
      "tensor(3.0866, grad_fn=<AddBackward0>)\n",
      "tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "tensor([0.1433, 0.3982], grad_fn=<SubBackward0>)\n",
      "tensor(2.6649, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor([0.6280, 0.6694], grad_fn=<SubBackward0>)\n",
      "tensor(3.0704, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.3831, 0.6950], grad_fn=<SubBackward0>)\n",
      "tensor(3.6710, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.3005, 0.4147], grad_fn=<SubBackward0>)\n",
      "tensor(3.0561, grad_fn=<AddBackward0>)\n",
      "tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "tensor([0.4078, 0.8100], grad_fn=<SubBackward0>)\n",
      "tensor(3.5400, grad_fn=<AddBackward0>)\n",
      "tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "tensor([0.5343, 0.6223], grad_fn=<SubBackward0>)\n",
      "tensor(3.5510, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.3899, 0.4962], grad_fn=<SubBackward0>)\n",
      "tensor(2.5794, grad_fn=<AddBackward0>)\n",
      "tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "tensor([0.5591, 0.6994], grad_fn=<SubBackward0>)\n",
      "tensor(2.7790, grad_fn=<AddBackward0>)\n",
      "tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "tensor([0.5879, 0.7180], grad_fn=<SubBackward0>)\n",
      "tensor(2.9140, grad_fn=<AddBackward0>)\n",
      "tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "tensor([0.5072, 0.8928], grad_fn=<SubBackward0>)\n",
      "tensor(2.9736, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.5061, 0.6170], grad_fn=<SubBackward0>)\n",
      "tensor(2.5419, grad_fn=<AddBackward0>)\n",
      "tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "tensor([0.2090, 0.7150], grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4e99bbf316b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m#compute the loss and propagate backwards\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\set-output\\dspn stuff\\DSPN.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, action_vec)\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0maction_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_vec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0maction_vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0maction_vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\set-output\\dspn stuff\\DSPN.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0eb1a734a1b5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_dim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# normalise so that activations aren't too high with big sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    257\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m    258\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 259\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rate = .0005\n",
    "\n",
    "dataset = newobjectdataset(\"newstate.csv\")\n",
    "\n",
    "setdimout = (1,2)  #(num objects, object length)\n",
    "setdimin = (1,14)\n",
    "iterator = torch.utils.data.DataLoader(dataset)\n",
    "\n",
    "##initialize encoder and DSPN encoder\n",
    "encoder1 = FSEncoder(14,32,32, setdimin)\n",
    "encoder2 = FSEncoder(2,32,32, setdimout)\n",
    "num_actions = 6\n",
    "\n",
    "#construct settoset network\n",
    "setnet = settoset(encoder1,encoder2,32,setdimout,10, masks = True)\n",
    "lambda1 = 6\n",
    "optimizer = optim.Adam(setnet.parameters(),lr = rate)\n",
    "running_loss = 0\n",
    "epochs = 12\n",
    "setnet.train()\n",
    "loss_func = hungarian_loss\n",
    "loss_func2 = nn.MSELoss()\n",
    "for e in range(epochs): \n",
    "    print(running_loss)\n",
    "    running_loss = 0\n",
    "    accuracy = 0\n",
    "    i = 0\n",
    "    torch.set_grad_enabled(True)\n",
    "    for set_,targetset_ in iterator: \n",
    "        i += 1\n",
    "        \n",
    "        if sum(targetset_[0]) == 0: \n",
    "            continue \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #All of this is because currently it is training to predict the next player position from the last one + action\n",
    "        set_.requires_grad = True\n",
    "        set_ = set_[0]\n",
    "        action = set_[-1*num_actions:]\n",
    "        set_ = set_[0:8]\n",
    "        \n",
    "        ##After reshaping the data from one long list back into sets, need to transpose it to get correct shape\n",
    "        targetset_ = targetset_[0][0:2].reshape(1,2).transpose(1,0)/10\n",
    "        \n",
    "        set_ = set_.reshape(int(len(set_)/8),8)\n",
    "        \n",
    "        set_ = torch.cat((set_,action.unsqueeze(0)),1)/10\n",
    "        \n",
    "        \n",
    "        \n",
    "     \n",
    "\n",
    "        out = setnet(set_)\n",
    "\n",
    "        #compute the loss and propagate backwards\n",
    "        loss =     loss_func(out,targetset_,setdimout) ##+ loss_func2(angle,setnet.encoder(set_))\n",
    "        \n",
    "     \n",
    "        loss.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        if i == 1000: \n",
    "            ##for parameter in setnet.parameters(): print(parameter)\n",
    "            print(running_loss) \n",
    "            print(loss)\n",
    "            running_loss = 0\n",
    "            print(out)\n",
    "            i = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_[0][-4] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1681,  0.7126], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setnet(set_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8000,  0.3000,  0.0000, -0.1000,  0.1000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
